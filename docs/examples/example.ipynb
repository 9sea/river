{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example we'll use a linear regression to forecast the number of available bikes in `bike stations <https://www.wikiwand.com/en/Bicycle-sharing_system>`_ from the city of Toulouse. Each observation looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'moment': datetime.datetime(2016, 4, 1, 0, 0, 7),\n",
       " 'station': 'metro-canal-du-midi',\n",
       " 'clouds': 75,\n",
       " 'description': 'light rain',\n",
       " 'humidity': 81,\n",
       " 'pressure': 1017.0,\n",
       " 'temperature': 6.54,\n",
       " 'wind': 9.3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from creme import datasets\n",
    "\n",
    "X_y = datasets.Bikes()\n",
    "x, y = next(iter(X_y))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bikes: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of bikes: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will include all the available numeric features in our model. We will also use target encoding by calculating a running average of the target per station and hour. Before being fed to the linear regression, the features will be scaled using a `preprocessing.StandardScaler`. Note that each of these steps works in a streaming fashion, including the feature extraction. We'll evaluate the model by asking it to forecast 30 minutes ahead while delaying the true answers, which ensures that we're simulating a production scenario. Finally we will print the current score every 20,000 predictions.\n",
    "\n",
    "We will now build a pipeline to learn from this stream of data. First of all we will use a `compose.Select` to select the numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import compose\n",
    "\n",
    "model = compose.Select('clouds', 'humidity', 'pressure', 'temperature', 'wind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we will perform target encoding by computing a running average of the number of bikes availables per station and per hour. In order to do we first have to extract the hour from the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import feature_extraction\n",
    "from creme import stats\n",
    "\n",
    "def add_hour(x):\n",
    "    x['hour'] = x['moment'].hour\n",
    "    return x\n",
    "\n",
    "model += (\n",
    "    add_hour |\n",
    "    feature_extraction.TargetAgg(by=['station', 'hour'], how=stats.Mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute a exponentially weighted average of the number of available per station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model += feature_extraction.TargetAgg(by='station', how=stats.EWMean(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now append to our model a linear regression. We will precede it with a `preprocessing.StandardScaler` in order to scale the data. Remember that for the moment we haven't processed any data, we're simply specifying a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import linear_model\n",
    "from creme import preprocessing\n",
    "\n",
    "model |= preprocessing.StandardScaler()\n",
    "model |= linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can now be used to learn and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_one(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.02\n",
      "0.0796\n",
      "0.07846533424818158\n",
      "0.27196896899252465\n",
      "0.12586570728081584\n",
      "0.44686768270921523\n",
      "0.2765384411157542\n",
      "0.7962402719642111\n",
      "0.6784020335332857\n"
     ]
    }
   ],
   "source": [
    "for x, y in X_y.take(10):\n",
    "    print(model.predict_one(x))\n",
    "    model.fit_one(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline can be visualized, either by printing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline (\n",
       "  TransformerUnion (\n",
       "    Select (\n",
       "      whitelist=('clouds', 'humidity', 'pressure', 'temperature', 'wind')\n",
       "    ),\n",
       "    Pipeline (\n",
       "      FuncTransformer (\n",
       "        func=\"add_hour\"\n",
       "      ),\n",
       "      TargetAgg (\n",
       "        by=['station', 'hour']\n",
       "        how=Mean ()\n",
       "        target_name=\"target\"\n",
       "      )\n",
       "    ),\n",
       "    TargetAgg (\n",
       "      by=['station']\n",
       "      how=EWMean (\n",
       "        alpha=0.5\n",
       "      )\n",
       "      target_name=\"target\"\n",
       "    )\n",
       "  ),\n",
       "  StandardScaler (\n",
       "    with_mean=True\n",
       "    with_std=True\n",
       "  ),\n",
       "  LinearRegression (\n",
       "    optimizer=SGD (\n",
       "      lr=InverseScaling (\n",
       "        learning_rate=0.01\n",
       "        power=0.25\n",
       "      )\n",
       "    )\n",
       "    loss=Squared ()\n",
       "    l2=0.\n",
       "    intercept=0.744521\n",
       "    intercept_lr=Constant (\n",
       "      learning_rate=0.01\n",
       "    )\n",
       "    clip_gradient=1e+12\n",
       "    initializer=Zeros ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by drawing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"577pt\" height=\"404pt\"\n",
       " viewBox=\"0.00 0.00 576.70 404.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 400)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-400 572.7,-400 572.7,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-width=\"1.2\" points=\"398.13,-396 344.13,-396 344.13,-360 398.13,-360 398.13,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"371.13\" y=\"-374.7\" font-family=\"trebuchet\" font-size=\"11.00\">x</text>\n",
       "</g>\n",
       "<!-- (&#39;clouds&#39;, &#39;humidity&#39;, &#39;pressure&#39;, &#39;temperature&#39;, &#39;wind&#39;) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>(&#39;clouds&#39;, &#39;humidity&#39;, &#39;pressure&#39;, &#39;temperature&#39;, &#39;wind&#39;)</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-width=\"1.2\" points=\"264.39,-252 -0.13,-252 -0.13,-216 264.39,-216 264.39,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"132.13\" y=\"-230.7\" font-family=\"trebuchet\" font-size=\"11.00\">(&#39;clouds&#39;, &#39;humidity&#39;, &#39;pressure&#39;, &#39;temperature&#39;, &#39;wind&#39;)</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;(&#39;clouds&#39;, &#39;humidity&#39;, &#39;pressure&#39;, &#39;temperature&#39;, &#39;wind&#39;) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;(&#39;clouds&#39;, &#39;humidity&#39;, &#39;pressure&#39;, &#39;temperature&#39;, &#39;wind&#39;)</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.6\" d=\"M343.71,-378C280.94,-378 132.13,-378 132.13,-378 132.13,-378 132.13,-262.24 132.13,-262.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"0.6\" points=\"135.63,-262.24 132.13,-252.24 128.63,-262.24 135.63,-262.24\"/>\n",
       "</g>\n",
       "<!-- add_hour -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>add_hour</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-width=\"1.2\" points=\"401.62,-324 340.64,-324 340.64,-288 401.62,-288 401.62,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"371.13\" y=\"-302.7\" font-family=\"trebuchet\" font-size=\"11.00\">add_hour</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;add_hour -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x&#45;&gt;add_hour</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.6\" d=\"M371.13,-359.83C371.13,-359.83 371.13,-334.41 371.13,-334.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"0.6\" points=\"374.63,-334.41 371.13,-324.41 367.63,-334.41 374.63,-334.41\"/>\n",
       "</g>\n",
       "<!-- target_ewm_0.5_by_station -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>target_ewm_0.5_by_station</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-width=\"1.2\" points=\"568.77,-324 419.49,-324 419.49,-288 568.77,-288 568.77,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.13\" y=\"-302.7\" font-family=\"trebuchet\" font-size=\"11.00\">target_ewm_0.5_by_station</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;target_ewm_0.5_by_station -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x&#45;&gt;target_ewm_0.5_by_station</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.6\" d=\"M398.43,-378C434.66,-378 494.13,-378 494.13,-378 494.13,-378 494.13,-334.17 494.13,-334.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"0.6\" points=\"497.63,-334.17 494.13,-324.17 490.63,-334.17 497.63,-334.17\"/>\n",
       "</g>\n",
       "<!-- StandardScaler -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>StandardScaler</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-width=\"1.2\" points=\"418.95,-180 329.31,-180 329.31,-144 418.95,-144 418.95,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"374.13\" y=\"-158.7\" font-family=\"trebuchet\" font-size=\"11.00\">StandardScaler</text>\n",
       "</g>\n",
       "<!-- (&#39;clouds&#39;, &#39;humidity&#39;, &#39;pressure&#39;, &#39;temperature&#39;, &#39;wind&#39;)&#45;&gt;StandardScaler -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>(&#39;clouds&#39;, &#39;humidity&#39;, &#39;pressure&#39;, &#39;temperature&#39;, &#39;wind&#39;)&#45;&gt;StandardScaler</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.6\" d=\"M132.13,-215.83C132.13,-194.5 132.13,-162 132.13,-162 132.13,-162 319.18,-162 319.18,-162\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"0.6\" points=\"319.18,-165.5 329.18,-162 319.18,-158.5 319.18,-165.5\"/>\n",
       "</g>\n",
       "<!-- target_mean_by_station_and_hour -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>target_mean_by_station_and_hour</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-width=\"1.2\" points=\"466.26,-252 282,-252 282,-216 466.26,-216 466.26,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"374.13\" y=\"-230.7\" font-family=\"trebuchet\" font-size=\"11.00\">target_mean_by_station_and_hour</text>\n",
       "</g>\n",
       "<!-- add_hour&#45;&gt;target_mean_by_station_and_hour -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>add_hour&#45;&gt;target_mean_by_station_and_hour</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.6\" d=\"M371.13,-287.83C371.13,-287.83 371.13,-262.41 371.13,-262.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"0.6\" points=\"374.63,-262.41 371.13,-252.41 367.63,-262.41 374.63,-262.41\"/>\n",
       "</g>\n",
       "<!-- target_mean_by_station_and_hour&#45;&gt;StandardScaler -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>target_mean_by_station_and_hour&#45;&gt;StandardScaler</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.6\" d=\"M374.13,-215.83C374.13,-215.83 374.13,-190.41 374.13,-190.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"0.6\" points=\"377.63,-190.41 374.13,-180.41 370.63,-190.41 377.63,-190.41\"/>\n",
       "</g>\n",
       "<!-- target_ewm_0.5_by_station&#45;&gt;StandardScaler -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>target_ewm_0.5_by_station&#45;&gt;StandardScaler</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.6\" d=\"M517.57,-287.76C517.57,-249.01 517.57,-162 517.57,-162 517.57,-162 429.12,-162 429.12,-162\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"0.6\" points=\"429.12,-158.5 419.12,-162 429.12,-165.5 429.12,-158.5\"/>\n",
       "</g>\n",
       "<!-- LinearRegression -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>LinearRegression</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-width=\"1.2\" points=\"424.35,-108 323.91,-108 323.91,-72 424.35,-72 424.35,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"374.13\" y=\"-86.7\" font-family=\"trebuchet\" font-size=\"11.00\">LinearRegression</text>\n",
       "</g>\n",
       "<!-- StandardScaler&#45;&gt;LinearRegression -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>StandardScaler&#45;&gt;LinearRegression</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.6\" d=\"M374.13,-143.83C374.13,-143.83 374.13,-118.41 374.13,-118.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"0.6\" points=\"377.63,-118.41 374.13,-108.41 370.63,-118.41 377.63,-118.41\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>y</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-width=\"1.2\" points=\"401.13,-36 347.13,-36 347.13,0 401.13,0 401.13,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"374.13\" y=\"-14.7\" font-family=\"trebuchet\" font-size=\"11.00\">y</text>\n",
       "</g>\n",
       "<!-- LinearRegression&#45;&gt;y -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>LinearRegression&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"0.6\" d=\"M374.13,-71.83C374.13,-71.83 374.13,-46.41 374.13,-46.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"0.6\" points=\"377.63,-46.41 374.13,-36.41 370.63,-46.41 377.63,-46.41\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1a20068490>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the ``debug_one`` method to inspect what is happening at each stage of our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Input\n",
      "--------\n",
      "clouds: 75 (int)\n",
      "description: light rain (str)\n",
      "humidity: 81 (int)\n",
      "moment: 2016-04-01 00:10:09 (datetime)\n",
      "pressure: 1,017.00000 (float)\n",
      "station: metro-canal-du-midi (str)\n",
      "temperature: 6.54000 (float)\n",
      "wind: 9.30000 (float)\n",
      "\n",
      "1. Transformer union\n",
      "--------------------\n",
      "    1.0 ('clouds', 'humidity', 'pressure', 'temperature', 'wind')\n",
      "    -------------------------------------------------------------\n",
      "    clouds: 75 (int)\n",
      "    humidity: 81 (int)\n",
      "    pressure: 1,017.00000 (float)\n",
      "    temperature: 6.54000 (float)\n",
      "    wind: 9.30000 (float)\n",
      "\n",
      "    1.1 add_hour | target_mean_by_station_and_hour\n",
      "    ----------------------------------------------\n",
      "    target_mean_by_station_and_hour: 1.00000 (float)\n",
      "\n",
      "    1.2 target_ewm_0.5_by_station\n",
      "    -----------------------------\n",
      "    target_ewm_0.5_by_station: 1.00000 (float)\n",
      "\n",
      "clouds: 75 (int)\n",
      "humidity: 81 (int)\n",
      "pressure: 1,017.00000 (float)\n",
      "target_ewm_0.5_by_station: 1.00000 (float)\n",
      "target_mean_by_station_and_hour: 1.00000 (float)\n",
      "temperature: 6.54000 (float)\n",
      "wind: 9.30000 (float)\n",
      "\n",
      "2. StandardScaler\n",
      "-----------------\n",
      "clouds: 0.00000 (float)\n",
      "humidity: 0.00000 (float)\n",
      "pressure: 0.00000 (float)\n",
      "target_ewm_0.5_by_station: -0.18757 (float)\n",
      "target_mean_by_station_and_hour: -0.18757 (float)\n",
      "temperature: 0.00000 (float)\n",
      "wind: 0.00000 (float)\n",
      "\n",
      "3. LinearRegression\n",
      "-------------------\n",
      "Name                              Value      Weight     Contribution  \n",
      "                      Intercept    1.00000    0.74452        0.74452  \n",
      "                           wind    0.00000    0.00000        0.00000  \n",
      "                    temperature    0.00000    0.00000        0.00000  \n",
      "                       pressure    0.00000    0.00000        0.00000  \n",
      "                       humidity    0.00000    0.00000        0.00000  \n",
      "                         clouds    0.00000    0.00000        0.00000  \n",
      "target_mean_by_station_and_hour   -0.18757    0.15843       -0.02972  \n",
      "      target_ewm_0.5_by_station   -0.18757    0.15843       -0.02972  \n",
      "\n",
      "Prediction: 0.68509\n"
     ]
    }
   ],
   "source": [
    "model.debug_one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of our model, we can use progressive validation. This consists in interleaving predictions with model updates, one after the other. In order to mimick a production scenario, we can delay the arrival of the ground truth so that model doesn't \"cheat\" by seeing it right after a prediction is made. This is all handled by the `model_selection.progressive_val_score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30,000] MAE: 2.187625\n",
      "[60,000] MAE: 2.246547\n",
      "[90,000] MAE: 2.286495\n",
      "[120,000] MAE: 2.263921\n",
      "[150,000] MAE: 2.266359\n",
      "[180,000] MAE: 2.281646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MAE: 2.285093"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from creme import metrics\n",
    "from creme import model_selection\n",
    "\n",
    "model_selection.progressive_val_score(\n",
    "    X_y=X_y,\n",
    "    model=model,\n",
    "    metric=metrics.MAE(),\n",
    "    moment='moment',\n",
    "    delay=dt.timedelta(minutes=30),\n",
    "    print_every=30_000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('creme': conda)",
   "language": "python",
   "name": "python37664bitcremeconda5d94adb7cd4041e592d9b5fc201b4bc9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
