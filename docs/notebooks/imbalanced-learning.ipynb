{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning it is quite usual to have to deal with imbalanced dataset. This is particularly true in online learning for tasks such as fraud detection and spam classification. In these two cases, which are binary classification problems, there are usually many more 0s than 1s, which generally hinders the performance of the classifiers we thrown at them.\n",
    "\n",
    "As an example we'll use the credit card dataset available in `creme`. We'll first use a `collections.Counter` to count the number of 0s and 1s in order to get an idea of the class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 284315 (99.82725%)\n",
      "1: 492 (0.17275%)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from creme import datasets\n",
    "\n",
    "X_y = datasets.CreditCard()\n",
    "\n",
    "counts = collections.Counter(y for _, y in X_y)\n",
    "\n",
    "for c, count in counts.items():\n",
    "    print(f'{c}: {count} ({count / sum(counts.values()):.5%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is quite unbalanced. For each 1 there are about 578 0s. Let's now train a logistic regression with default parameters and see how well it does. We'll measure the ROC AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,000] ROCAUC: 0.899341\n",
      "[30,000] ROCAUC: 0.87079\n",
      "[45,000] ROCAUC: 0.899804\n",
      "[60,000] ROCAUC: 0.89192\n",
      "[75,000] ROCAUC: 0.890126\n",
      "[90,000] ROCAUC: 0.897645\n",
      "[105,000] ROCAUC: 0.889682\n",
      "[120,000] ROCAUC: 0.886271\n",
      "[135,000] ROCAUC: 0.883233\n",
      "[150,000] ROCAUC: 0.885329\n",
      "[165,000] ROCAUC: 0.897751\n",
      "[180,000] ROCAUC: 0.896706\n",
      "[195,000] ROCAUC: 0.896068\n",
      "[210,000] ROCAUC: 0.894425\n",
      "[225,000] ROCAUC: 0.893745\n",
      "[240,000] ROCAUC: 0.893375\n",
      "[255,000] ROCAUC: 0.89189\n",
      "[270,000] ROCAUC: 0.893778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: 0.891071"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from creme import linear_model\n",
    "from creme import metrics\n",
    "from creme import model_selection\n",
    "from creme import preprocessing\n",
    "\n",
    "\n",
    "X_y = datasets.CreditCard()\n",
    "\n",
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "\n",
    "model_selection.progressive_val_score(\n",
    "    X_y,\n",
    "    model,\n",
    "    metric,\n",
    "    print_every=15_000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is already quite acceptable, but as we will now see we can do even better. The first thing we can do is to add weight to the 1s by using the `class_weight` argument of the `LogisticRegression` class. Under the hood this will increase the magnitude of the gradient. Intuitively this helps the model on rare examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,000] ROCAUC: 0.907733\n",
      "[30,000] ROCAUC: 0.913497\n",
      "[45,000] ROCAUC: 0.935347\n",
      "[60,000] ROCAUC: 0.92263\n",
      "[75,000] ROCAUC: 0.917461\n",
      "[90,000] ROCAUC: 0.923706\n",
      "[105,000] ROCAUC: 0.913346\n",
      "[120,000] ROCAUC: 0.910504\n",
      "[135,000] ROCAUC: 0.909895\n",
      "[150,000] ROCAUC: 0.909142\n",
      "[165,000] ROCAUC: 0.918603\n",
      "[180,000] ROCAUC: 0.918592\n",
      "[195,000] ROCAUC: 0.916969\n",
      "[210,000] ROCAUC: 0.915904\n",
      "[225,000] ROCAUC: 0.915336\n",
      "[240,000] ROCAUC: 0.915016\n",
      "[255,000] ROCAUC: 0.914223\n",
      "[270,000] ROCAUC: 0.915509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: 0.912311"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from creme import datasets\n",
    "from creme import linear_model\n",
    "from creme import metrics\n",
    "from creme import model_selection\n",
    "from creme import preprocessing\n",
    "\n",
    "\n",
    "X_y = datasets.CreditCard()\n",
    "\n",
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.LogisticRegression(\n",
    "        class_weights={0: 1, 1: 4}\n",
    "    )\n",
    ")\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "\n",
    "model_selection.progressive_val_score(\n",
    "    X_y,\n",
    "    model,\n",
    "    metric,\n",
    "    print_every=15_000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding importance weights only works with gradient-based models (which includes neural networks). A more generic, and potentially more effective approach, is to use undersamplig and oversampling. As an example, we'll under-sample the stream so that our logistic regression encounter 20% of 1s and 80% of 0s. Under-sampling has the additional benefit of requiring less training steps, and thus reduces the total training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,000] ROCAUC: 0.939633\n",
      "[30,000] ROCAUC: 0.954278\n",
      "[45,000] ROCAUC: 0.969119\n",
      "[60,000] ROCAUC: 0.9602\n",
      "[75,000] ROCAUC: 0.955892\n",
      "[90,000] ROCAUC: 0.961742\n",
      "[105,000] ROCAUC: 0.95182\n",
      "[120,000] ROCAUC: 0.948409\n",
      "[135,000] ROCAUC: 0.949267\n",
      "[150,000] ROCAUC: 0.952339\n",
      "[165,000] ROCAUC: 0.955113\n",
      "[180,000] ROCAUC: 0.954583\n",
      "[195,000] ROCAUC: 0.953861\n",
      "[210,000] ROCAUC: 0.954009\n",
      "[225,000] ROCAUC: 0.951322\n",
      "[240,000] ROCAUC: 0.953741\n",
      "[255,000] ROCAUC: 0.952319\n",
      "[270,000] ROCAUC: 0.953518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: 0.950284"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from creme import imblearn\n",
    "\n",
    "\n",
    "X_y = datasets.CreditCard()\n",
    "\n",
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    imblearn.RandomUnderSampler(\n",
    "        classifier=linear_model.LogisticRegression(),\n",
    "        desired_dist={0: .8, 1: .2},\n",
    "        seed=42\n",
    "    )\n",
    ")\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "\n",
    "model_selection.progressive_val_score(\n",
    "    X_y,\n",
    "    model,\n",
    "    metric,\n",
    "    print_every=15_000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RandomUnderSampler` is a wrapper for classifiers. This is represented by a rectangle around the logistic regression bubble when we draw the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"198pt\" height=\"263pt\"\n",
       " viewBox=\"0.00 0.00 198.00 263.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 259)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-259 194,-259 194,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_RandomUnderSampler</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"8,-64 8,-139 182,-139 182,-64 8,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">RandomUnderSampler</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"95\" cy=\"-237\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-233.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x</text>\n",
       "</g>\n",
       "<!-- StandardScaler -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>StandardScaler</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"95\" cy=\"-165\" rx=\"63.8893\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-161.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">StandardScaler</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;StandardScaler -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;StandardScaler</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M95,-218.8314C95,-211.131 95,-201.9743 95,-193.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.5001,-193.4132 95,-183.4133 91.5001,-193.4133 98.5001,-193.4132\"/>\n",
       "</g>\n",
       "<!-- LogisticRegression -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>LogisticRegression</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"95\" cy=\"-90\" rx=\"78.7863\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LogisticRegression</text>\n",
       "</g>\n",
       "<!-- StandardScaler&#45;&gt;LogisticRegression -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>StandardScaler&#45;&gt;LogisticRegression</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M95,-146.8446C95,-138.3401 95,-128.0076 95,-118.4964\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.5001,-118.2481 95,-108.2482 91.5001,-118.2482 98.5001,-118.2481\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"95\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- LogisticRegression&#45;&gt;y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>LogisticRegression&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M95,-71.8314C95,-64.131 95,-54.9743 95,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.5001,-46.4132 95,-36.4133 91.5001,-46.4133 98.5001,-46.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fdf664e7a10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
